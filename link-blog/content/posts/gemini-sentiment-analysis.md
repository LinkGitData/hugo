---
title: "Project Spotlight: Gemini Sentiment Analysis & Entity Recognition"
date: 2025-12-08T11:57:00+08:00
draft: false
tags: ["Generative AI", "Gemini", "Flask", "Python", "Sentiment Analysis"]
categories: ["AI Projects"]
cover:
  image: "images/ai-cover.png" # Temporary: reusing the manga style cover
  alt: "Gemini Sentiment Analysis"
  caption: "Powered by Gemini 1.5 Flash"
  relative: false
---

In this post, we'll dive into an exciting open-source project that leverages Google's **Gemini 1.5 Flash** model to perform advanced sentiment analysis and entity recognition on text. This project, `gemini-sentiment-web`, demonstrates how to integrate modern Generative AI into a simple Flask web application.

## ğŸŒŸ Project Overview

The core goal of this application is to take a piece of text (like a customer review or social media comment) and automatically:

1.  **Analyze Sentiment**: Determine if the tone is Positive, Neutral, or Negative (with 7 levels of granularity).
2.  **Extract Entities**: Identify key people, places, or products mentioned.
3.  **Auto-Labeling**: Assign specific tags like "Product Quality (Positive)" or "Service (Negative)".
4.  **Explain**: Provide a reason for the analysis, making the AI transparent.

## ğŸ› ï¸ Tech Stack

*   **Backend**: Python, Flask
*   **AI Model**: Google Vertex AI (Gemini 1.5 Flash)
*   **Monitoring**: Sentry (for error tracking)
*   **Deployment**: Docker / Cloud Run ready (Procfile included)

## ğŸ’» Code Deep Dive

Let's look at how the magic happens in `app.py`.

### 1. Model Initialization

First, we utilize the `vertexai.preview.generative_models` library to load the **Gemini 1.5 Flash** model. Note the system instruction giving the AI a persona.

```python
model = GenerativeModel(
    "gemini-1.5-flash-001",
    system_instruction=["""ä½ æ˜¯å¾ˆæ£’çš„è©•è«–å®¶ï¼Œä½ çš„æœå‹™å¾ˆæœ‰å¹«åŠ©"""]
)
```

### 2. Prompt Engineering

The most critical part of any GenAI application is the prompt. This project uses a structured prompt to guide Gemini's output into a specific format that the code can parse easily.

```python
def analyze_text(text):
    response = model.generate_content(
        f"""åˆ†æä»¥ä¸‹æ–‡å­—çš„æƒ…ç·’ï¼Œä¸¦æ¨™è¨»å…¶ä¸­çš„å¯¦é«”ä¸”è‡ªå‹•è²¼æ¨™ï¼š
        "{text}"
        æƒ…ç·’æ‡‰ç‚ºä»¥ä¸‹å…¶ä¸­ä¹‹ä¸€ï¼šéå¸¸æ­£é¢ã€æ­£é¢ã€ç¨å¾®æ­£é¢ã€ä¸­æ€§ã€ç¨å¾®è² é¢ã€è² é¢ã€éå¸¸è² é¢ã€‚
        å¯¦é«”å¯ä»¥æ˜¯äººåã€åœ°åã€çµ„ç¹”åã€ç”¢å“åç­‰ã€‚
        è‡ªå‹•è²¼æ¨™å¯ä»¥æ˜¯ç‰›è‚‰éºµå“è³ª(æ­£é¢)ã€ç‚’é£¯å“è³ª(è² é¢)ã€æœå‹™(æ­£é¢)ã€ç’°å¢ƒ(ä¸­æ€§)ã€ç­‰å€™æˆ–è™•ç†æ™‚é–“(è² é¢)ã€åƒ¹æ ¼ï¼ˆæ­£é¢ï¼‰ç­‰ã€‚
        è«‹ç”¨ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
        æƒ…ç·’: <æƒ…ç·’>
        è§£é‡‹: <æƒ…ç·’è§£é‡‹>
        Geminiçš„è§£é‡‹: <Geminiè‡ªå·±çš„æƒ…ç·’è§£é‡‹>
        å¯¦é«”: <å¯¦é«”1>, <å¯¦é«”2>, ...
        è‡ªå‹•è²¼æ¨™: <æ¨™ç±¤1>, <æ¨™ç±¤2>, ...
        """,
        # ... config
    )
    return response
```

### 3. Safety Settings & Configuration

To ensure the AI produces safe and concise content, we configure `max_output_tokens` and safety thresholds.

```python
generation_config = {
    "max_output_tokens": 256,
    "temperature": 1.0,
}

safety_settings = {
    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    # ... other categories
}
```

## ğŸš€ Why This Matters

This project illustrates the "Agent-First" approach to software development. Instead of training a custom sentiment model from scratch (which requires massive datasets and compute), we simply **orchestrate** a powerful pre-trained LLM (Gemini) to do the heavy lifting.

This approach drastically reduces development time and allows developers to focus on the **application logic** and **user experience** rather than the underlying ML infrastructure.

---

*Check out the full source code on GitHub: [LinkGitData/gemini-sentiment-web](https://github.com/LinkGitData/gemini-sentiment-web)*
